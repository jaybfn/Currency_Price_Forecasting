{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade --no-cache-dir git+https://github.com/StreamAlpha/tvdatafeed.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "\n",
    "from tvDatafeed import TvDatafeed, Interval\n",
    "from credential import tradingview as settings\n",
    "\n",
    "username = settings['username']\n",
    "password = settings['password']\n",
    "\n",
    "tv = TvDatafeed(username, password)\n",
    "\n",
    "def get_historical_data(tv, symbol_exchange_dict, interval, n_bars):\n",
    "    result = {}\n",
    "    for symbol, exchange in symbol_exchange_dict.items():\n",
    "        data = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars)\n",
    "        data.reset_index(inplace=True)\n",
    "        result[symbol] = data\n",
    "    return result\n",
    "\n",
    "# Create an instance of TvDatafeed class\n",
    "tv = TvDatafeed(username, password)\n",
    "\n",
    "# Define symbol and exchange dictionary\n",
    "symbol_exchange_dict = {\n",
    "    'XAUUSD': 'OANDA',\n",
    "    'DXY': 'TVC',\n",
    "    'USOIL': 'TVC',\n",
    "    'USINTR': 'ECONOMICS',\n",
    "    'SPX500USD': 'OANDA'\n",
    "}\n",
    "\n",
    "# Get historical data for symbols and exchanges in the dictionary\n",
    "historical_data = get_historical_data(tv, symbol_exchange_dict, interval=Interval.in_daily, n_bars=10000)\n",
    "\n",
    "# Access individual dataframes\n",
    "gold_data = historical_data['XAUUSD']\n",
    "dollarIndex_data = historical_data['DXY']\n",
    "oil_data = historical_data['USOIL']\n",
    "interestrate_data = historical_data['USINTR']\n",
    "SP500 = historical_data['SPX500USD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TvDatafeed(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_data(tv, symbol_exchange_dict, interval, n_bars):\n",
    "    result = {}\n",
    "    for symbol, exchange in symbol_exchange_dict.items():\n",
    "        data = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars)\n",
    "        data.reset_index(inplace=True)\n",
    "        result[symbol] = data\n",
    "    return result\n",
    "\n",
    "# Create an instance of TvDatafeed class\n",
    "tv = TvDatafeed(username, password)\n",
    "\n",
    "# Define symbol and exchange dictionary\n",
    "symbol_exchange_dict = {\n",
    "    'XAUUSD': 'OANDA',\n",
    "    'DXY': 'TVC',\n",
    "    'USOIL': 'TVC',\n",
    "    'USINTR': 'ECONOMICS',\n",
    "    'SPX500USD': 'OANDA'\n",
    "}\n",
    "\n",
    "# Get historical data for symbols and exchanges in the dictionary\n",
    "historical_data = get_historical_data(tv, symbol_exchange_dict, interval=Interval.in_daily, n_bars=10000)\n",
    "\n",
    "# Access individual dataframes\n",
    "gold_data = historical_data['XAUUSD']\n",
    "dollarIndex_data = historical_data['DXY']\n",
    "oil_data = historical_data['USOIL']\n",
    "interestrate_data = historical_data['USINTR']\n",
    "SP500 = historical_data['SPX500USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index\n",
    "gold_data = tv.get_hist(symbol='XAUUSD',exchange='OANDA',interval=Interval.in_daily,n_bars=10000)\n",
    "\n",
    "# futures continuous contract\n",
    "#nifty_futures_data = tv.get_hist(symbol='NIFTY',exchange='NSE',interval=Interval.in_1_hour,n_bars=1000,fut_contract=1)\n",
    "\n",
    "# crudeoil\n",
    "#crudeoil_data = tv.get_hist(symbol='CRUDEOIL',exchange='MCX',interval=Interval.in_1_hour,n_bars=5000,fut_contract=1)\n",
    "\n",
    "# downloading data for extended market hours\n",
    "#extended_price_data = tv.get_hist(symbol=\"EICHERMOT\",exchange=\"NSE\",interval=Interval.in_1_hour,n_bars=500, extended_session=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data = gold_data.reset_index()\n",
    "gold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollarIndex_data = tv.get_hist(symbol='DXY',exchange='TVC',interval=Interval.in_daily,n_bars=10000)\n",
    "dollarIndex_data.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollarIndex_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_data = tv.get_hist(symbol='USOIL',exchange='TVC',interval=Interval.in_daily,n_bars=10000)\n",
    "oil_data.reset_index(inplace = True)\n",
    "oil_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interestrate_data = tv.get_hist(symbol='USINTR',exchange='ECONOMICS',interval=Interval.in_daily,n_bars=10000)\n",
    "interestrate_data.reset_index(inplace = True)\n",
    "interestrate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500 = tv.get_hist(symbol='SPX500USD',exchange = 'OANDA',interval=Interval.in_daily,n_bars=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500.reset_index(inplace = True)\n",
    "SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from tvDatafeed import TvDatafeed, Interval\n",
    "from sqlalchemy import create_engine, Column, Integer, Date, Float, func\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from datetime import datetime\n",
    "from sqlalchemy import inspect\n",
    "from session import *\n",
    "import logging\n",
    "from datetime import datetime, date \n",
    "from pandas._libs.tslibs.timestamps import Timestamp \n",
    "\n",
    "# Configure logging for the program\n",
    "logging.basicConfig(filename='tradingview_data_extraction.log', level=logging.DEBUG)\n",
    "logging.info(\"Program started at {}\".format(datetime.now()))\n",
    "\n",
    "# Define SQLAlchemy Base\n",
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "\n",
    "# Function to create the SQLAlchemy engine and session\n",
    "# def get_engine_from_settings():\n",
    "#     engine = create_engine('postgresql://postgres:postgres@localhost:5432/currencydb')\n",
    "#     return engine\n",
    "\n",
    "# def get_session():\n",
    "#     engine = get_engine_from_settings()\n",
    "#     Session = sessionmaker(bind=engine)\n",
    "#     session = Session()\n",
    "#     return session\n",
    "\n",
    "def Sessions():\n",
    "    \"\"\"\n",
    "    Function to create the SQLAlchemy engine and session\n",
    "    Returns:\n",
    "        session object\n",
    "    \"\"\"\n",
    "    engine = get_engine_from_settings()\n",
    "    Base.metadata.create_all(bind=engine)\n",
    "    session = get_session()\n",
    "    return session\n",
    "\n",
    "# Function to check if a table exists in the database\n",
    "def table_exists(session, table_name):\n",
    "    return session.connection().execute(\n",
    "        f\"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = '{table_name}')\"\n",
    "    ).scalar()\n",
    "\n",
    "# Function to get the latest date in a table\n",
    "# def get_latest_date(session, table_name):\n",
    "#     latest_date = session.query(func.max(User.datetime)).filter(User.__table__.name == table_name).scalar()\n",
    "#     return latest_date\n",
    "\n",
    "\n",
    "\n",
    "# Function to create table structure using SQLAlchemy ORM\n",
    "def create_table(table_name, Base):\n",
    "    \"\"\"\n",
    "    Function to create table structure using SQLAlchemy ORM\n",
    "    Args:\n",
    "        table_name : name of the table to be created\n",
    "        Base       : SQLAlchemy Base object\n",
    "        engine     : SQLAlchemy engine object\n",
    "    Returns:\n",
    "        User       : SQLAlchemy ORM Class for the table\n",
    "    \"\"\"\n",
    "    \n",
    "    engine = get_engine_from_settings()\n",
    "    class User(Base):\n",
    "        __tablename__ = table_name\n",
    "        id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "        datetime = Column(Date, nullable=False)\n",
    "        open = Column(Float)\n",
    "        high = Column(Float)\n",
    "        low = Column(Float)\n",
    "        close = Column(Float)\n",
    "        volume = Column(Float)\n",
    "        \n",
    "    inspector = inspect(engine)\n",
    "    #if engine.has_table(table_name):\n",
    "    if inspector.has_table(table_name):\n",
    "        # if table exists, overwrite it\n",
    "        User.__table__.drop(engine)\n",
    "        User.__table__.create(engine)\n",
    "    else:\n",
    "        # if table does not exist, create it\n",
    "        Base.metadata.create_all(engine)\n",
    "        \n",
    "    return User\n",
    "\n",
    "\n",
    "# Function to fetch historical data from TradingView API\n",
    "def get_historical_data(tv, symbol_exchange_dict, interval, n_bars):\n",
    "    result = {}\n",
    "    for symbol, exchange in symbol_exchange_dict.items():\n",
    "        data = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars)\n",
    "        data.reset_index(inplace=True)\n",
    "        result[symbol] = data\n",
    "    return result\n",
    "\n",
    "\n",
    "def load_data_to_postgres_db(Base,currency_symbol,historical_data, session):\n",
    "    \n",
    "    name = currency_symbol.lower()+'_'+'data'\n",
    "    table_name = name\n",
    "    # Create SQLAlchemy Base object and User class using the create_table function\n",
    "    #Base = declarative_base()\n",
    "    User = create_table(table_name, Base)\n",
    "\n",
    "    # Log the start of data insertion into the database\n",
    "    logging.info(\"Start inserting data into {}\".format(table_name))\n",
    "    # Insert the data into the database using the bulk_insert_mappings method\n",
    "    # Convert the Python dictionary to a Pandas DataFrame\n",
    "    # historical_df = pd.DataFrame.from_dict(historical_data, orient='columns')\n",
    "    session.bulk_insert_mappings(User,historical_data.to_dict(orient='records'))\n",
    "    # Commit the transaction to save the changes to the database\n",
    "    session.commit()\n",
    "    # Log the completion of data insertion and the successful completion of the program\n",
    "    logging.info(\"Data insertion completed at {}\".format(datetime.now()))\n",
    "    logging.info(\"Program completed successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "# # Function to insert data into PostgreSQL table\n",
    "# def extract_load_data_to_postgres_db(Base, currency_symbol, historical_data, session):\n",
    "#     name = currency_symbol.lower() + '_' + 'data'\n",
    "#     table_name = name\n",
    "#     User = create_table(table_name, Base)\n",
    "#     logging.info(\"Start inserting data into {}\".format(table_name))\n",
    "    \n",
    "#     # Convert 'datetime' column to datetime64[ns] objects\n",
    "#     historical_data['datetime'] = pd.to_datetime(historical_data['datetime'])\n",
    "    \n",
    "#     # Convert latest_date to Timestamp if not None\n",
    "#     latest_date = pd.to_datetime(latest_date) if latest_date is not None else None\n",
    "    \n",
    "#     new_data = historical_data[historical_data['datetime'] > latest_date] if latest_date is not None else historical_data\n",
    "    \n",
    "#     session.bulk_insert_mappings(User, new_data.to_dict(orient='records'))\n",
    "#     session.commit()\n",
    "#     logging.info(\"Data insertion completed at {}\".format(datetime.now()))\n",
    "#     logging.info(\"Program completed successfully.\")\n",
    "\n",
    "\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# def append_data_to_postgres_db(Base, currency_symbol, new_data, session):\n",
    "#     name = currency_symbol.lower() + '_' + 'data'\n",
    "#     table_name = name\n",
    "\n",
    "#     # Assuming that 'User' is the SQLAlchemy model for your existing table\n",
    "#     User = Base.metadata.tables[table_name]\n",
    "#     print(Base.metadata.tables.keys())\n",
    "\n",
    "\n",
    "#     # # Log the start of data insertion into the database\n",
    "#     # logging.info(\"Start appending data to {}\".format(table_name))\n",
    "\n",
    "#     # # Insert the new data into the existing table\n",
    "#     # session.bulk_insert_mappings(User, new_data.to_dict(orient='records'))\n",
    "\n",
    "#     # # Commit the transaction to save the changes to the database\n",
    "#     # session.commit()\n",
    "\n",
    "#     # # Log the completion of data insertion and the successful completion of the program\n",
    "#     # logging.info(\"Data append completed at {}\".format(datetime.now()))\n",
    "#     # logging.info(\"Program completed successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'jb0109@protonmail.com'\n",
    "password = 'Lambo@01091990'\n",
    "\n",
    "tv = TvDatafeed(username, password)\n",
    "\n",
    "# Define symbol and exchange dictionary\n",
    "symbol_exchange_dict = {\n",
    "    'XAUUSD': 'OANDA',\n",
    "    'DXY': 'TVC',\n",
    "    'USOIL': 'TVC',\n",
    "    'USINTR': 'ECONOMICS',\n",
    "    'SPX500USD': 'OANDA'\n",
    "}\n",
    "\n",
    "# Get historical data for symbols and exchanges in the dictionary\n",
    "#historical_data = get_historical_data(tv, symbol_exchange_dict, interval=Interval.in_daily, n_bars=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQLAlchemy session\n",
    "#session = get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_date(session, table_name):\n",
    "    # Define your SQL query to select the latest date from the table\n",
    "    sql_query = f\"SELECT max(datetime) FROM {table_name} LIMIT 5\"\n",
    "#max(datetime)\n",
    "    # Execute the query and fetch the result\n",
    "    result = session.connection().execute(sql_query)\n",
    "    \n",
    "    # Fetch the first row (which contains the latest date)\n",
    "    latest_date = result.fetchone()[0]\n",
    "\n",
    "    #Check if the latest_date is not None, and then format and print it\n",
    "    if latest_date:\n",
    "        formatted_date = latest_date.strftime('%Y-%m-%d')\n",
    "        return formatted_date\n",
    "    else:\n",
    "        return (\"No data found in the table.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "# Iterate over the dictionary items\n",
    "for symbol in symbol_exchange_dict.keys():\n",
    "    symbol_name = symbol\n",
    "    table_name = symbol_name.lower() + '_data'\n",
    "    #print(table_name)\n",
    "    if not table_exists(session, table_name):\n",
    "        #User = create_table(table_name, Base)\n",
    "        historical_data = get_historical_data(tv, symbol_exchange_dict, interval=Interval.in_daily, n_bars=10000)\n",
    "        for symbol, data in historical_data.items():\n",
    "            symbol_name, symbol_data = symbol, data\n",
    "            #extract_load_data_to_postgres_db(Base, symbol_name, symbol_data, session)\n",
    "            load_data_to_postgres_db(Base,symbol_name,historical_data, session)\n",
    "    else:\n",
    "        print(table_name)\n",
    "        latest_date = get_latest_date(session, table_name)\n",
    "        latest_date = pd.to_datetime(latest_date)\n",
    "        new_historical_data = get_historical_data(tv, symbol_exchange_dict, interval=Interval.in_daily, n_bars=100)\n",
    "        for symbol, data in new_historical_data.items():\n",
    "            # Access individual symbol and data\n",
    "            symbol_name, symbol_data = symbol, data\n",
    "            data = symbol_data.loc[symbol_data['datetime'].dt.date > latest_date.date()]\n",
    "            #append_data_to_postgres_db(Base, symbol_name, data, session)\n",
    "        #print(latest_date)\n",
    "        print(data)\n",
    "        \n",
    "        \n",
    "        \n",
    "            #print(symbol_name, symbol_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvDatafeed import TvDatafeed, Interval\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import logging\n",
    "from sqlalchemy import Table, Column, Integer, Date, String, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import inspect\n",
    "# local files\n",
    "from session import *\n",
    "from datetime import datetime, date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging for the program\n",
    "logging.basicConfig(filename='tradingview_data_extraction.log', level=logging.DEBUG)\n",
    "logging.info(\"Program started at {}\".format(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sessions():\n",
    "    \"\"\"\n",
    "    Function to create the SQLAlchemy engine and session\n",
    "    Returns:\n",
    "        session object\n",
    "    \"\"\"\n",
    "    engine = get_engine_from_settings()\n",
    "    DynamicBase.metadata.create_all(bind=engine)\n",
    "    session = get_session()\n",
    "    return session\n",
    "\n",
    "# datetime\tsymbol\topen\thigh\tlow\tclose\tvolume\n",
    "def create_table(table_name, Base):\n",
    "    \"\"\"\n",
    "    Function to create table structure using SQLAlchemy ORM\n",
    "    Args:\n",
    "        table_name : name of the table to be created\n",
    "        Base       : SQLAlchemy Base object\n",
    "        engine     : SQLAlchemy engine object\n",
    "    Returns:\n",
    "        User       : SQLAlchemy ORM Class for the table\n",
    "    \"\"\"\n",
    "    \n",
    "    engine = get_engine_from_settings()\n",
    "    #DynamicBase = declarative_base(class_registry=dict())\n",
    "    class User(DynamicBase):\n",
    "            __tablename__ = table_name\n",
    "            id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "            datetime = Column(Date) #nullable=False\n",
    "            open = Column(Float)\n",
    "            high = Column(Float)\n",
    "            low = Column(Float)\n",
    "            close = Column(Float)\n",
    "            volume = Column(Float)\n",
    "        \n",
    "    inspector = inspect(engine)\n",
    "    #if engine.has_table(table_name):\n",
    "    if inspector.has_table(table_name):\n",
    "        # if table exists, overwrite it\n",
    "        User.__table__.drop(engine)\n",
    "        User.__table__.create(engine)\n",
    "    else:\n",
    "        # if table does not exist, create it\n",
    "        Base.metadata.create_all(engine)\n",
    "        \n",
    "    return User\n",
    "\n",
    "def get_historical_data(tv, symbol_exchange_dict, interval, n_bars):\n",
    "    result = {}\n",
    "    for symbol, exchange in symbol_exchange_dict.items():\n",
    "        data = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars)\n",
    "        data.reset_index(inplace=True)\n",
    "        result[symbol] = data\n",
    "    return result\n",
    "\n",
    "def extract_load_data_to_postgres_db(Base,currency_symbol,historical_data):\n",
    "\n",
    "    name = currency_symbol.lower()+'_'+'data'\n",
    "    table_name = name\n",
    "    # Create SQLAlchemy Base object and User class using the create_table function\n",
    "    #Base = declarative_base()\n",
    "    User = create_table(table_name, Base)\n",
    "    # Create a SQLAlchemy session\n",
    "    session = Sessions()\n",
    "\n",
    "    # Log the start of data insertion into the database\n",
    "    logging.info(\"Start inserting data into {}\".format(table_name))\n",
    "    # Insert the data into the database using the bulk_insert_mappings method\n",
    "    #session.bulk_insert_mappings(User,historical_data.to_dict(orient='records'))\n",
    "    session.bulk_insert_mappings(User,historical_data.to_dict(orient='records'))\n",
    "    # Commit the transaction to save the changes to the database\n",
    "    session.commit()\n",
    "    # Log the completion of data insertion and the successful completion of the program\n",
    "    logging.info(\"Data insertion completed at {}\".format(datetime.now()))\n",
    "    logging.info(\"Program completed successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "def get_latest_date(session, table_name):\n",
    "    # Define your SQL query to select the latest date from the table\n",
    "    sql_query = f\"SELECT max(datetime) FROM {table_name} LIMIT 5\"\n",
    "    #max(datetime)\n",
    "    # Execute the query and fetch the result\n",
    "    result = session.connection().execute(sql_query)\n",
    "    \n",
    "    # Fetch the first row (which contains the latest date)\n",
    "    latest_date = result.fetchone()[0]\n",
    "\n",
    "    #Check if the latest_date is not None, and then format and print it\n",
    "    if latest_date:\n",
    "        formatted_date = latest_date.strftime('%Y-%m-%d')\n",
    "        return formatted_date\n",
    "    else:\n",
    "        return (\"No data found in the table.\")\n",
    "    \n",
    "\n",
    "# Function to check if a table exists in the database\n",
    "def table_exists(session, table_name):\n",
    "    return session.connection().execute(\n",
    "        f\"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = '{table_name}')\"\n",
    "    ).scalar()\n",
    "\n",
    "\n",
    "def load_data_to_postgres_db(Base,currency_symbol,historical_data, session):\n",
    "    \n",
    "    name = currency_symbol.lower()+'_'+'data'\n",
    "    table_name = name\n",
    "    # Create SQLAlchemy Base object and User class using the create_table function\n",
    "    #Base = declarative_base()\n",
    "    User = create_table(table_name, Base)\n",
    "\n",
    "    # Log the start of data insertion into the database\n",
    "    logging.info(\"Start inserting data into {}\".format(table_name))\n",
    "    # Insert the data into the database using the bulk_insert_mappings method\n",
    "    # Convert the Python dictionary to a Pandas DataFrame\n",
    "    # historical_df = pd.DataFrame.from_dict(historical_data, orient='columns')\n",
    "    #session.bulk_insert_mappings(User,historical_data.to_dict(orient='records'))\n",
    "    session.bulk_insert_mappings(User,historical_data.to_dict(orient='records'))\n",
    "    # Commit the transaction to save the changes to the database\n",
    "    session.commit()\n",
    "    # Log the completion of data insertion and the successful completion of the program\n",
    "    logging.info(\"Data insertion completed at {}\".format(datetime.now()))\n",
    "    logging.info(\"Program completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DynamicBase = declarative_base()\n",
    "username = 'jb0109@protonmail.com'\n",
    "password = 'Lambo@01091990'\n",
    "\n",
    "tv = TvDatafeed(username, password)\n",
    "\n",
    "# Define symbol and exchange dictionary\n",
    "symbol_exchange_dict = {\n",
    "    'XAUUSD': 'OANDA',\n",
    "    'DXY': 'TVC',\n",
    "    'USOIL': 'TVC',\n",
    "    'USINTR': 'ECONOMICS',\n",
    "    'SPX500USD': 'OANDA'\n",
    "}\n",
    "\n",
    "# Get historical data for symbols and exchanges in the dictionary\n",
    "#historical_data = get_historical_data(tv, symbol_exchange_dict, interval=Interval.in_daily, n_bars=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import insert\n",
    "\n",
    "session = Sessions()\n",
    "# Iterate over the dictionary items\n",
    "for symbol in symbol_exchange_dict.keys():\n",
    "    symbol_name = symbol\n",
    "    table_name = symbol_name.lower() + '_data'\n",
    "    #print(table_name)\n",
    "\n",
    "    if not table_exists(session, table_name):\n",
    "        #User = create_table(table_name, Base)\n",
    "        historical_data = get_historical_data(tv, symbol_exchange_dict, interval=Interval.in_daily, n_bars=10000)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        latest_date = get_latest_date(session, table_name)\n",
    "        latest_date = pd.to_datetime(latest_date)\n",
    "        new_historical_data = get_historical_data(tv, symbol_exchange_dict, interval=Interval.in_daily, n_bars=100)\n",
    "        # for symbol, data in new_historical_data.items():\n",
    "        #     # Access individual symbol and data\n",
    "        #     symbol_name, symbol_data = symbol, data\n",
    "        #     data = symbol_data.loc[symbol_data['datetime'].dt.date > latest_date.date()]\n",
    "            #append_data_to_postgres_db(Base, symbol_name, data, session)\n",
    "        #print(latest_date)\n",
    "        #print(data)\n",
    "\n",
    "\n",
    "# for symbol, data in historical_data.items():\n",
    "#     symbol_name, symbol_data = symbol, data\n",
    "#     print(symbol_data.head())\n",
    "#     #print(type(symbol_data.to_dict(orient='records')))\n",
    "#     #extract_load_data_to_postgres_db(Base, symbol_name, symbol_data, session)\n",
    "#     load_data_to_postgres_db(DynamicBase ,symbol_name,symbol_data, session)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "User = create_table(table_name, DynamicBase)\n",
    "for symbol, data in new_historical_data.items():\n",
    "    symbol_name, symbol_data = symbol, data\n",
    "    print(symbol_data.head())\n",
    "    \n",
    "    insert_stmt = insert(User).values(symbol_data.to_dict(orient='records'))\n",
    "    \n",
    "        #print(symbol_name, symbol_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(new_historical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_historical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b90cab7ea642421f44636989edaf96d86cb1abe354b45ce6eed3b362842c2584"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
